{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåç Disaster COG Processing\n",
    "\n",
    "This simplified notebook converts disaster imagery to Cloud Optimized GeoTIFFs (COGs).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Step 1: Configuration\n",
    "\n",
    "Modify the configuration below with your event details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CONFIGURATION - MODIFY THESE VALUES\n",
    "# ========================================\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Event Details\n",
    "EVENT_NAME = '202408_TropicalStorm_Debby'  # Your disaster event name\n",
    "PRODUCT_NAME = 'landsat8'                   # Product type (sentinel1, sentinel2, landsat, etc.)\n",
    "\n",
    "# S3 Paths\n",
    "BUCKET = 'nasa-disasters'                                          # S3 bucket\n",
    "SOURCE_PATH = f'drcs_activations/{EVENT_NAME}/{PRODUCT_NAME}'      # Where your files are\n",
    "DESTINATION_BASE = 'drcs_activations_new'                          # Where to save COGs\n",
    "\n",
    "# Processing Options\n",
    "OVERWRITE = False  # Set to True to replace existing files\n",
    "VERIFY = True      # Set to True to verify results after processing\n",
    "\n",
    "# ========================================\n",
    "# FILENAME GENERATION FUNCTIONS\n",
    "# Modify these to control output filenames\n",
    "# ========================================\n",
    "\n",
    "def extract_date_from_filename(filename):\n",
    "    \"\"\"Extract date from filename in YYYYMMDD format.\"\"\"\n",
    "    dates = re.findall(r'\\d{8}', filename)\n",
    "    if dates:\n",
    "        date_str = dates[0]\n",
    "        return f\"{date_str[0:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "    return None\n",
    "\n",
    "def create_truecolor_filename(original_path, event_name):\n",
    "    \"\"\"Create filename for trueColor products.\"\"\"\n",
    "    filename = os.path.basename(original_path)\n",
    "    stem = os.path.splitext(filename)[0]\n",
    "    date = extract_date_from_filename(stem)\n",
    "    \n",
    "    if date:\n",
    "        stem_clean = re.sub(r'_\\d{8}', '', stem)\n",
    "        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n",
    "    return f\"{event_name}_{stem}_day.tif\"\n",
    "\n",
    "def create_colorinfrared_filename(original_path, event_name):\n",
    "    \"\"\"Create filename for colorInfrared products.\"\"\"\n",
    "    filename = os.path.basename(original_path)\n",
    "    stem = os.path.splitext(filename)[0]\n",
    "    date = extract_date_from_filename(stem)\n",
    "    \n",
    "    if date:\n",
    "        stem_clean = re.sub(r'_\\d{8}', '', stem)\n",
    "        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n",
    "    return f\"{event_name}_{stem}_day.tif\"\n",
    "\n",
    "def create_naturalcolor_filename(original_path, event_name):\n",
    "    \"\"\"Create filename for naturalColor products.\"\"\"\n",
    "    filename = os.path.basename(original_path)\n",
    "    stem = os.path.splitext(filename)[0]\n",
    "    date = extract_date_from_filename(stem)\n",
    "    \n",
    "    if date:\n",
    "        stem_clean = re.sub(r'_\\d{8}', '', stem)\n",
    "        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n",
    "    return f\"{event_name}_{stem}_day.tif\"\n",
    "\n",
    "# Map product types to filename creators\n",
    "FILENAME_CREATORS = {\n",
    "    'trueColor': create_truecolor_filename,\n",
    "    'colorInfrared': create_colorinfrared_filename,\n",
    "    'naturalColor': create_naturalcolor_filename,\n",
    "    # Add more as needed for your products\n",
    "}\n",
    "\n",
    "# Optional: Override output directories for each category\n",
    "OUTPUT_DIRS = {\n",
    "    'trueColor': 'Landsat/trueColor',\n",
    "    'colorInfrared': 'Landsat/colorIR',\n",
    "    'naturalColor': 'Landsat/naturalColor',\n",
    "    # Defaults will be used for categories not listed here\n",
    "}\n",
    "\n",
    "# Optional: Manual no-data values (None = auto-detect)\n",
    "NODATA_VALUES = {\n",
    "    'NDVI': -9999,\n",
    "    'MNDWI': -9999,\n",
    "    # Leave empty or set to None for auto-detection\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"Event: {EVENT_NAME}\")\n",
    "print(f\"Source: s3://{BUCKET}/{SOURCE_PATH}\")\n",
    "print(f\"Destination: s3://{BUCKET}/{DESTINATION_BASE}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 2: Import and Initialize\n",
    "\n",
    "This cell imports all necessary modules and connects to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the simplified processor\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path('..').resolve()))\n",
    "\n",
    "# Import our simplified helper\n",
    "from notebooks.notebook_helpers import SimpleProcessor\n",
    "\n",
    "# Create configuration\n",
    "config = {\n",
    "    'event_name': EVENT_NAME,\n",
    "    'bucket': BUCKET,\n",
    "    'source_path': SOURCE_PATH,\n",
    "    'destination_base': DESTINATION_BASE,\n",
    "    'overwrite': OVERWRITE,\n",
    "    'verify': VERIFY,\n",
    "    'filename_creators': FILENAME_CREATORS,\n",
    "    'output_dirs': OUTPUT_DIRS,\n",
    "    'nodata_values': NODATA_VALUES\n",
    "}\n",
    "\n",
    "# Initialize processor\n",
    "processor = SimpleProcessor(config)\n",
    "\n",
    "# Connect to S3\n",
    "if processor.connect_to_s3():\n",
    "    print(\"‚úÖ Ready to process files\")\n",
    "else:\n",
    "    print(\"‚ùå Could not connect to S3. Check your AWS credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 3: Discover Files and Preview\n",
    "\n",
    "This cell finds your files and shows what will be processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover files\n",
    "num_files = processor.discover_files()\n",
    "\n",
    "if num_files > 0:\n",
    "    # Show preview of what will be processed\n",
    "    processor.preview_processing()\n",
    "    \n",
    "    print(\"\\nüìå Review the preview above. If filenames look incorrect,\")\n",
    "    print(\"   modify the filename creator functions in Step 1.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No files found. Check your SOURCE_PATH setting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 4: Process Files\n",
    "\n",
    "Run this cell to start processing all files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all files\n",
    "if num_files > 0:\n",
    "    print(\"üöÄ Starting processing...\")\n",
    "    print(\"This may take several minutes depending on file sizes.\\n\")\n",
    "    \n",
    "    # Process everything\n",
    "    results = processor.process_all()\n",
    "    \n",
    "    # Display results\n",
    "    if not results.empty:\n",
    "        print(\"\\nüìä Detailed Results:\")\n",
    "        display(results) if 'display' in dir() else print(results)\n",
    "else:\n",
    "    print(\"No files to process. Run Step 3 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 5: Review Results (Optional)\n",
    "\n",
    "View detailed results and statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "if 'results' in locals() and not results.empty:\n",
    "    print(\"üìä PROCESSING STATISTICS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Success rate\n",
    "    total = len(results)\n",
    "    success = len(results[results['status'] == 'success'])\n",
    "    failed = len(results[results['status'] == 'failed'])\n",
    "    skipped = len(results[results['status'] == 'skipped'])\n",
    "    \n",
    "    print(f\"Total files: {total}\")\n",
    "    print(f\"‚úÖ Success: {success}\")\n",
    "    print(f\"‚ùå Failed: {failed}\")\n",
    "    print(f\"‚è≠Ô∏è Skipped: {skipped}\")\n",
    "    print(f\"\\nSuccess rate: {(success/total*100):.1f}%\")\n",
    "    \n",
    "    # Failed files\n",
    "    if failed > 0:\n",
    "        print(\"\\n‚ùå Failed files:\")\n",
    "        failed_df = results[results['status'] == 'failed']\n",
    "        for idx, row in failed_df.iterrows():\n",
    "            print(f\"  - {row['file']}: {row.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    # Processing times\n",
    "    if 'time_seconds' in results.columns:\n",
    "        success_df = results[results['status'] == 'success']\n",
    "        if not success_df.empty:\n",
    "            avg_time = success_df['time_seconds'].mean()\n",
    "            max_time = success_df['time_seconds'].max()\n",
    "            print(f\"\\n‚è±Ô∏è Timing:\")\n",
    "            print(f\"Average: {avg_time:.1f} seconds per file\")\n",
    "            print(f\"Slowest: {max_time:.1f} seconds\")\n",
    "else:\n",
    "    print(\"No results to analyze. Run Step 4 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Tips & Troubleshooting\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "1. **\"No files found\"**\n",
    "   - Check that `SOURCE_PATH` is correct\n",
    "   - Verify files exist in S3: `aws s3 ls s3://bucket/path/`\n",
    "\n",
    "2. **\"Failed to connect to S3\"**\n",
    "   - Check AWS credentials: `aws configure list`\n",
    "   - Ensure you have access to the bucket\n",
    "\n",
    "3. **Files being skipped**\n",
    "   - Files already exist in destination\n",
    "   - Set `OVERWRITE = True` to reprocess\n",
    "\n",
    "4. **Processing is slow**\n",
    "   - Large files take time\n",
    "   - System uses optimized GDAL processing automatically\n",
    "\n",
    "5. **Wrong filenames**\n",
    "   - Modify the filename creator functions in Step 1\n",
    "   - Re-run from Step 3 to see preview\n",
    "\n",
    "### Need More Control?\n",
    "\n",
    "Use the full template at `disaster_processing_template.ipynb` for:\n",
    "- Manual chunk configuration\n",
    "- Custom processing parameters\n",
    "- Detailed verification options\n",
    "- Advanced memory management"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
