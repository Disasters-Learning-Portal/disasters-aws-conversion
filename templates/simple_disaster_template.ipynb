{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåç Simple Disaster COG Processing\n",
    "\n",
    "This simplified notebook converts disaster satellite imagery to Cloud Optimized GeoTIFFs (COGs) with just a few cells.\n",
    "\n",
    "## ‚ú® Features\n",
    "- **See files first** - List S3 files before configuring\n",
    "- **Smart configuration** - Define filename functions after seeing actual files\n",
    "- **Auto-discovery** - Automatically categorizes your files\n",
    "- **Simple processing** - Just run the cells in order\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Step 1: Basic Configuration\n",
    "\n",
    "Set your event details and S3 paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# BASIC CONFIGURATION\n",
    "# ========================================\n",
    "\n",
    "# Event Details\n",
    "EVENT_NAME = '202408_TropicalStorm_Debby'  # Your disaster event name\n",
    "PRODUCT_NAME = 'landsat8'                   # Product type (sentinel1, sentinel2, landsat, etc.)\n",
    "\n",
    "# S3 Paths\n",
    "BUCKET = 'nasa-disasters'                                          # S3 bucket\n",
    "SOURCE_PATH = f'drcs_activations/{EVENT_NAME}/{PRODUCT_NAME}'      # Where your files are\n",
    "DESTINATION_BASE = 'drcs_activations_new'                          # Where to save COGs\n",
    "\n",
    "# Processing Options\n",
    "OVERWRITE = False  # Set to True to replace existing files\n",
    "VERIFY = True      # Set to True to verify results after processing\n",
    "\n",
    "print(\"‚úÖ Basic configuration loaded\")\n",
    "print(f\"Event: {EVENT_NAME}\")\n",
    "print(f\"Source: s3://{BUCKET}/{SOURCE_PATH}\")\n",
    "print(f\"Destination: s3://{BUCKET}/{DESTINATION_BASE}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 2: Connect to S3 and List Files\n",
    "\n",
    "Let's see what files are available before configuring filename transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ========================================\n# FILENAME GENERATION FUNCTIONS\n# Modify these based on the files you see above\n# ========================================\n\nimport re\n\ndef extract_date_from_filename(filename):\n    \"\"\"Extract date from filename in YYYYMMDD format.\"\"\"\n    dates = re.findall(r'\\d{8}', filename)\n    if dates:\n        date_str = dates[0]\n        return f\"{date_str[0:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n    return None\n\ndef create_truecolor_filename(original_path, event_name):\n    \"\"\"Create filename for trueColor products.\"\"\"\n    filename = os.path.basename(original_path)\n    stem = os.path.splitext(filename)[0]\n    date = extract_date_from_filename(stem)\n    \n    if date:\n        stem_clean = re.sub(r'_\\d{8}', '', stem)\n        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n    return f\"{event_name}_{stem}_day.tif\"\n\ndef create_colorinfrared_filename(original_path, event_name):\n    \"\"\"Create filename for colorInfrared products.\"\"\"\n    filename = os.path.basename(original_path)\n    stem = os.path.splitext(filename)[0]\n    date = extract_date_from_filename(stem)\n    \n    if date:\n        stem_clean = re.sub(r'_\\d{8}', '', stem)\n        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n    return f\"{event_name}_{stem}_day.tif\"\n\ndef create_naturalcolor_filename(original_path, event_name):\n    \"\"\"Create filename for naturalColor products.\"\"\"\n    filename = os.path.basename(original_path)\n    stem = os.path.splitext(filename)[0]\n    date = extract_date_from_filename(stem)\n    \n    if date:\n        stem_clean = re.sub(r'_\\d{8}', '', stem)\n        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n    return f\"{event_name}_{stem}_day.tif\"\n\ndef create_generic_filename(original_path, event_name):\n    \"\"\"Generic filename creator for any file type.\"\"\"\n    filename = os.path.basename(original_path)\n    stem = os.path.splitext(filename)[0]\n    date = extract_date_from_filename(stem)\n    \n    if date:\n        stem_clean = re.sub(r'_\\d{8}', '', stem)\n        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n    return f\"{event_name}_{stem}_day.tif\"\n\n# Map product types to filename creators\n# IMPORTANT: Include 'other' to handle uncategorized files\nFILENAME_CREATORS = {\n    'trueColor': create_truecolor_filename,\n    'colorInfrared': create_colorinfrared_filename,\n    'naturalColor': create_naturalcolor_filename,\n    'other': create_generic_filename,  # Handle uncategorized files\n    # Add more mappings as needed based on your files\n}\n\n# Optional: Override output directories for each category\n# IMPORTANT: Include 'other' to control where uncategorized files go\nOUTPUT_DIRS = {\n    'trueColor': 'Landsat/trueColor',\n    'colorInfrared': 'Landsat/colorIR',\n    'naturalColor': 'Landsat/naturalColor',\n    'other': 'Landsat/other',  # Specify where uncategorized files go\n    # Add more as needed\n}\n\n# Optional: Manual no-data values (None = auto-detect)\nNODATA_VALUES = {\n    'NDVI': -9999,\n    'MNDWI': -9999,\n    # Leave empty or set to None for auto-detection\n}\n\nprint(\"‚úÖ Filename functions defined\")\nprint(f\"\\nüìÇ Output directories configured:\")\nfor category, path in OUTPUT_DIRS.items():\n    print(f\"   ‚Ä¢ {category} ‚Üí {DESTINATION_BASE}/{path}\")\n\n# Test with a sample filename if files exist\nif files:\n    sample_file = files[0]\n    sample_name = os.path.basename(sample_file)\n    \n    # Try to detect which function to use\n    if 'trueColor' in sample_name or 'truecolor' in sample_name:\n        new_name = create_truecolor_filename(sample_file, EVENT_NAME)\n    elif 'colorInfrared' in sample_name or 'colorIR' in sample_name:\n        new_name = create_colorinfrared_filename(sample_file, EVENT_NAME)\n    elif 'naturalColor' in sample_name:\n        new_name = create_naturalcolor_filename(sample_file, EVENT_NAME)\n    else:\n        new_name = create_generic_filename(sample_file, EVENT_NAME)\n    \n    print(f\"\\nüìù Example transformation:\")\n    print(f\"   Original: {sample_name}\")\n    print(f\"   ‚Üí New:    {new_name}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üè∑Ô∏è Step 3: Define Categorization and Filename Transformations\n\nBased on the files you see above, configure:\n1. **Categorization patterns** - Regex patterns to identify file types\n2. **Filename functions** - How to transform filenames\n3. **Output directories** - Where each category should be saved"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ========================================\n# CATEGORIZATION AND OUTPUT CONFIGURATION\n# ========================================\n\nimport re\n\n# STEP 1: Define how to extract dates from filenames\ndef extract_date_from_filename(filename):\n    \"\"\"Extract date from filename in YYYYMMDD format.\"\"\"\n    dates = re.findall(r'\\d{8}', filename)\n    if dates:\n        date_str = dates[0]\n        return f\"{date_str[0:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n    return None\n\n# STEP 2: Define filename transformation functions for each category\ndef create_truecolor_filename(original_path, event_name):\n    \"\"\"Create filename for trueColor products.\"\"\"\n    filename = os.path.basename(original_path)\n    stem = os.path.splitext(filename)[0]\n    date = extract_date_from_filename(stem)\n    \n    if date:\n        stem_clean = re.sub(r'_\\d{8}', '', stem)\n        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n    return f\"{event_name}_{stem}_day.tif\"\n\ndef create_colorinfrared_filename(original_path, event_name):\n    \"\"\"Create filename for colorInfrared products.\"\"\"\n    filename = os.path.basename(original_path)\n    stem = os.path.splitext(filename)[0]\n    date = extract_date_from_filename(stem)\n    \n    if date:\n        stem_clean = re.sub(r'_\\d{8}', '', stem)\n        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n    return f\"{event_name}_{stem}_day.tif\"\n\ndef create_naturalcolor_filename(original_path, event_name):\n    \"\"\"Create filename for naturalColor products.\"\"\"\n    filename = os.path.basename(original_path)\n    stem = os.path.splitext(filename)[0]\n    date = extract_date_from_filename(stem)\n    \n    if date:\n        stem_clean = re.sub(r'_\\d{8}', '', stem)\n        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n    return f\"{event_name}_{stem}_day.tif\"\n\n# STEP 3: Configure categorization patterns (REQUIRED)\n# These regex patterns determine which files belong to which category\nCATEGORIZATION_PATTERNS = {\n    'trueColor': r'trueColor|truecolor|true_color',\n    'colorInfrared': r'colorInfrared|colorIR|color_infrared',\n    'naturalColor': r'naturalColor|natural_color',\n    # Add patterns for ALL file types you want to process\n    # Files not matching any pattern will be skipped with a warning\n}\n\n# STEP 4: Map categories to filename transformation functions\nFILENAME_CREATORS = {\n    'trueColor': create_truecolor_filename,\n    'colorInfrared': create_colorinfrared_filename,\n    'naturalColor': create_naturalcolor_filename,\n    # Must have an entry for each category in CATEGORIZATION_PATTERNS\n}\n\n# STEP 5: Specify output directories for each category\nOUTPUT_DIRS = {\n    'trueColor': 'Landsat/trueColor',\n    'colorInfrared': 'Landsat/colorIR',\n    'naturalColor': 'Landsat/naturalColor',\n    # Must have an entry for each category in CATEGORIZATION_PATTERNS\n}\n\n# OPTIONAL: Specify no-data values (None = auto-detect)\nNODATA_VALUES = {\n    'NDVI': -9999,\n    'MNDWI': -9999,\n    # Leave empty or set to None for auto-detection\n}\n\nprint(\"‚úÖ Configuration defined\")\nprint(f\"\\nüìÇ Categories and output paths:\")\nfor category, path in OUTPUT_DIRS.items():\n    pattern = CATEGORIZATION_PATTERNS.get(category, 'No pattern defined')\n    print(f\"   ‚Ä¢ {category}:\")\n    print(f\"     Pattern: {pattern}\")\n    print(f\"     Output:  {DESTINATION_BASE}/{path}\")\n\n# Test with sample filename if files exist\nif files:\n    sample_file = files[0]\n    sample_name = os.path.basename(sample_file)\n    \n    # Check which category it would match\n    matched_category = None\n    for cat, pattern in CATEGORIZATION_PATTERNS.items():\n        if re.search(pattern, sample_name, re.IGNORECASE):\n            matched_category = cat\n            break\n    \n    if matched_category:\n        new_name = FILENAME_CREATORS[matched_category](sample_file, EVENT_NAME)\n        print(f\"\\nüìù Example transformation:\")\n        print(f\"   Original: {sample_name}\")\n        print(f\"   Category: {matched_category}\")\n        print(f\"   ‚Üí New:    {new_name}\")\n        print(f\"   ‚Üí Output: {DESTINATION_BASE}/{OUTPUT_DIRS[matched_category]}/{new_name}\")\n    else:\n        print(f\"\\n‚ö†Ô∏è Warning: Sample file doesn't match any category pattern:\")\n        print(f\"   File: {sample_name}\")\n        print(f\"   Add a pattern to CATEGORIZATION_PATTERNS to process this file type\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: Initialize Processor and Preview\n",
    "\n",
    "Now let's set up the processor and preview all transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import our simplified helper\nfrom notebooks.notebook_helpers import SimpleProcessor\n\n# Create full configuration with categorization patterns\nconfig = {\n    'event_name': EVENT_NAME,\n    'bucket': BUCKET,\n    'source_path': SOURCE_PATH,\n    'destination_base': DESTINATION_BASE,\n    'overwrite': OVERWRITE,\n    'verify': VERIFY,\n    'categorization_patterns': CATEGORIZATION_PATTERNS,  # IMPORTANT: Include patterns\n    'filename_creators': FILENAME_CREATORS,\n    'output_dirs': OUTPUT_DIRS,\n    'nodata_values': NODATA_VALUES\n}\n\n# Initialize processor\nprocessor = SimpleProcessor(config)\n\n# Connect to S3 (already connected, but needed for processor)\nif processor.connect_to_s3():\n    print(\"‚úÖ Processor ready\\n\")\n    \n    # Discover and categorize files\n    num_files = processor.discover_files()\n    \n    if num_files > 0:\n        # Show preview of transformations\n        processor.preview_processing()\n        \n        print(\"\\nüìå Review the transformations above.\")\n        print(\"   ‚Ä¢ Files will be saved to the directories specified in OUTPUT_DIRS\")\n        print(\"   ‚Ä¢ If files appear as 'uncategorized', add patterns to CATEGORIZATION_PATTERNS\")\n        print(\"   ‚Ä¢ When ready, proceed to Step 5 to process the files.\")\n    else:\n        print(\"‚ö†Ô∏è No files found to process.\")\nelse:\n    print(\"‚ùå Could not initialize processor.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 5: Process Files\n",
    "\n",
    "Run this cell to start processing all files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all files\n",
    "if 'num_files' in locals() and num_files > 0:\n",
    "    print(\"üöÄ Starting processing...\")\n",
    "    print(\"This may take several minutes depending on file sizes.\\n\")\n",
    "    \n",
    "    # Process everything\n",
    "    results = processor.process_all()\n",
    "    \n",
    "    # Display results\n",
    "    if not results.empty:\n",
    "        print(\"\\nüìä Processing Complete!\")\n",
    "        display(results) if 'display' in dir() else print(results)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No files to process. Complete Steps 1-4 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 6: Review Results (Optional)\n",
    "\n",
    "View detailed results and statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "if 'results' in locals() and not results.empty:\n",
    "    print(\"üìä PROCESSING STATISTICS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Success rate\n",
    "    total = len(results)\n",
    "    success = len(results[results['status'] == 'success'])\n",
    "    failed = len(results[results['status'] == 'failed'])\n",
    "    skipped = len(results[results['status'] == 'skipped'])\n",
    "    \n",
    "    print(f\"Total files: {total}\")\n",
    "    print(f\"‚úÖ Success: {success}\")\n",
    "    print(f\"‚ùå Failed: {failed}\")\n",
    "    print(f\"‚è≠Ô∏è Skipped: {skipped}\")\n",
    "    print(f\"\\nSuccess rate: {(success/total*100):.1f}%\")\n",
    "    \n",
    "    # Failed files\n",
    "    if failed > 0:\n",
    "        print(\"\\n‚ùå Failed files:\")\n",
    "        failed_df = results[results['status'] == 'failed']\n",
    "        for idx, row in failed_df.iterrows():\n",
    "            print(f\"  - {row['file']}: {row.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    # Processing times\n",
    "    if 'time_seconds' in results.columns:\n",
    "        success_df = results[results['status'] == 'success']\n",
    "        if not success_df.empty:\n",
    "            avg_time = success_df['time_seconds'].mean()\n",
    "            max_time = success_df['time_seconds'].max()\n",
    "            print(f\"\\n‚è±Ô∏è Timing:\")\n",
    "            print(f\"Average: {avg_time:.1f} seconds per file\")\n",
    "            print(f\"Slowest: {max_time:.1f} seconds\")\n",
    "else:\n",
    "    print(\"No results to analyze. Run Step 5 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Tips & Troubleshooting\n",
    "\n",
    "### Workflow Summary:\n",
    "1. **Configure** basic settings (Step 1)\n",
    "2. **List files** from S3 to see naming patterns (Step 2)\n",
    "3. **Define functions** to transform filenames (Step 3)\n",
    "4. **Preview** transformations (Step 4)\n",
    "5. **Process** all files (Step 5)\n",
    "6. **Review** results (Step 6)\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "1. **\"No files found\"**\n",
    "   - Check `SOURCE_PATH` in Step 1\n",
    "   - Verify bucket permissions\n",
    "   - Ensure files have `.tif` extension\n",
    "\n",
    "2. **Wrong filename transformations**\n",
    "   - Review actual filenames in Step 2\n",
    "   - Adjust functions in Step 3\n",
    "   - Re-run Step 4 to preview\n",
    "\n",
    "3. **Files being skipped**\n",
    "   - Files already exist in destination\n",
    "   - Set `OVERWRITE = True` in Step 1\n",
    "\n",
    "4. **Processing errors**\n",
    "   - Check AWS credentials\n",
    "   - Verify S3 write permissions\n",
    "   - Check available disk space for temp files\n",
    "\n",
    "### Need More Control?\n",
    "\n",
    "Use the full template at `disaster_processing_template.ipynb` for:\n",
    "- Manual chunk configuration\n",
    "- Custom compression settings\n",
    "- Detailed memory management\n",
    "- Advanced processing options"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}