{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåç Simple Disaster COG Processing\n",
    "\n",
    "This simplified notebook converts disaster satellite imagery to Cloud Optimized GeoTIFFs (COGs) with just a few cells.\n",
    "\n",
    "## ‚ú® Features\n",
    "- **See files first** - List S3 files before configuring\n",
    "- **Smart configuration** - Define filename functions after seeing actual files\n",
    "- **Auto-discovery** - Automatically categorizes your files\n",
    "- **Simple processing** - Just run the cells in order\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Step 1: Basic Configuration\n",
    "\n",
    "Set your event details and S3 paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Basic configuration loaded\n",
      "Event: 202408_TropicalStorm_Debby\n",
      "Source: s3://nasa-disasters/drcs_activations/202408_TropicalStorm_Debby/landsat8\n",
      "Destination: s3://nasa-disasters/drcs_activations_new/\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# BASIC CONFIGURATION\n",
    "# ========================================\n",
    "\n",
    "# Event Details\n",
    "EVENT_NAME = '202408_TropicalStorm_Debby'  # Your disaster event name\n",
    "PRODUCT_NAME = 'landsat8'                   # Product type (sentinel1, sentinel2, landsat, etc.)\n",
    "\n",
    "# S3 Paths\n",
    "BUCKET = 'nasa-disasters'                                          # S3 bucket\n",
    "SOURCE_PATH = f'drcs_activations/{EVENT_NAME}/{PRODUCT_NAME}'      # Where your files are\n",
    "DESTINATION_BASE = 'drcs_activations_new'                          # Where to save COGs\n",
    "\n",
    "# Processing Options\n",
    "OVERWRITE = False  # Set to True to replace existing files\n",
    "VERIFY = True      # Set to True to verify results after processing\n",
    "\n",
    "print(\"‚úÖ Basic configuration loaded\")\n",
    "print(f\"Event: {EVENT_NAME}\")\n",
    "print(f\"Source: s3://{BUCKET}/{SOURCE_PATH}\")\n",
    "print(f\"Destination: s3://{BUCKET}/{DESTINATION_BASE}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 2: Connect to S3 and List Files\n",
    "\n",
    "Let's see what files are available before configuring filename transformations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Step 3: Define Categorization and Filename Transformations\n",
    "\n",
    "Based on the files you see above, configure:\n",
    "1. **Categorization patterns** - Regex patterns to identify file types\n",
    "2. **Filename functions** - How to transform filenames\n",
    "3. **Output directories** - Where each category should be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration defined\n",
      "\n",
      "üìÇ Categories and output paths:\n",
      "   ‚Ä¢ trueColor:\n",
      "     Pattern: trueColor|truecolor|true_color\n",
      "     Output:  drcs_activations_new/Landsat/trueColor\n",
      "   ‚Ä¢ colorInfrared:\n",
      "     Pattern: colorInfrared|colorIR|color_infrared\n",
      "     Output:  drcs_activations_new/Landsat/colorIR\n",
      "   ‚Ä¢ naturalColor:\n",
      "     Pattern: naturalColor|natural_color\n",
      "     Output:  drcs_activations_new/Landsat/naturalColor\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m     Output:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDESTINATION_BASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Test with sample filename if files exist\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfiles\u001b[49m:\n\u001b[32m     93\u001b[39m     sample_file = files[\u001b[32m0\u001b[39m]\n\u001b[32m     94\u001b[39m     sample_name = os.path.basename(sample_file)\n",
      "\u001b[31mNameError\u001b[39m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CATEGORIZATION AND OUTPUT CONFIGURATION\n",
    "# ========================================\n",
    "\n",
    "import re\n",
    "\n",
    "# STEP 1: Define how to extract dates from filenames\n",
    "def extract_date_from_filename(filename):\n",
    "    \"\"\"Extract date from filename in YYYYMMDD format.\"\"\"\n",
    "    dates = re.findall(r'\\d{8}', filename)\n",
    "    if dates:\n",
    "        date_str = dates[0]\n",
    "        return f\"{date_str[0:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "    return None\n",
    "\n",
    "# STEP 2: Define filename transformation functions for each category\n",
    "def create_truecolor_filename(original_path, event_name):\n",
    "    \"\"\"Create filename for trueColor products.\"\"\"\n",
    "    filename = os.path.basename(original_path)\n",
    "    stem = os.path.splitext(filename)[0]\n",
    "    date = extract_date_from_filename(stem)\n",
    "    \n",
    "    if date:\n",
    "        stem_clean = re.sub(r'_\\d{8}', '', stem)\n",
    "        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n",
    "    return f\"{event_name}_{stem}_day.tif\"\n",
    "\n",
    "def create_colorinfrared_filename(original_path, event_name):\n",
    "    \"\"\"Create filename for colorInfrared products.\"\"\"\n",
    "    filename = os.path.basename(original_path)\n",
    "    stem = os.path.splitext(filename)[0]\n",
    "    date = extract_date_from_filename(stem)\n",
    "    \n",
    "    if date:\n",
    "        stem_clean = re.sub(r'_\\d{8}', '', stem)\n",
    "        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n",
    "    return f\"{event_name}_{stem}_day.tif\"\n",
    "\n",
    "def create_naturalcolor_filename(original_path, event_name):\n",
    "    \"\"\"Create filename for naturalColor products.\"\"\"\n",
    "    filename = os.path.basename(original_path)\n",
    "    stem = os.path.splitext(filename)[0]\n",
    "    date = extract_date_from_filename(stem)\n",
    "    \n",
    "    if date:\n",
    "        stem_clean = re.sub(r'_\\d{8}', '', stem)\n",
    "        return f\"{event_name}_{stem_clean}_{date}_day.tif\"\n",
    "    return f\"{event_name}_{stem}_day.tif\"\n",
    "\n",
    "# STEP 3: Configure categorization patterns (REQUIRED)\n",
    "# These regex patterns determine which files belong to which category\n",
    "CATEGORIZATION_PATTERNS = {\n",
    "    'trueColor': r'trueColor|truecolor|true_color',\n",
    "    'colorInfrared': r'colorInfrared|colorIR|color_infrared',\n",
    "    'naturalColor': r'naturalColor|natural_color',\n",
    "    # Add patterns for ALL file types you want to process\n",
    "    # Files not matching any pattern will be skipped with a warning\n",
    "}\n",
    "\n",
    "# STEP 4: Map categories to filename transformation functions\n",
    "FILENAME_CREATORS = {\n",
    "    'trueColor': create_truecolor_filename,\n",
    "    'colorInfrared': create_colorinfrared_filename,\n",
    "    'naturalColor': create_naturalcolor_filename,\n",
    "    # Must have an entry for each category in CATEGORIZATION_PATTERNS\n",
    "}\n",
    "\n",
    "# STEP 5: Specify output directories for each category\n",
    "OUTPUT_DIRS = {\n",
    "    'trueColor': 'Landsat/trueColor',\n",
    "    'colorInfrared': 'Landsat/colorIR',\n",
    "    'naturalColor': 'Landsat/naturalColor',\n",
    "    # Must have an entry for each category in CATEGORIZATION_PATTERNS\n",
    "}\n",
    "\n",
    "# OPTIONAL: Specify no-data values (None = auto-detect)\n",
    "NODATA_VALUES = {\n",
    "    'NDVI': -9999,\n",
    "    'MNDWI': -9999,\n",
    "    # Leave empty or set to None for auto-detection\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration defined\")\n",
    "print(f\"\\nüìÇ Categories and output paths:\")\n",
    "for category, path in OUTPUT_DIRS.items():\n",
    "    pattern = CATEGORIZATION_PATTERNS.get(category, 'No pattern defined')\n",
    "    print(f\"   ‚Ä¢ {category}:\")\n",
    "    print(f\"     Pattern: {pattern}\")\n",
    "    print(f\"     Output:  {DESTINATION_BASE}/{path}\")\n",
    "\n",
    "# Test with sample filename if files exist\n",
    "if files:\n",
    "    sample_file = files[0]\n",
    "    sample_name = os.path.basename(sample_file)\n",
    "    \n",
    "    # Check which category it would match\n",
    "    matched_category = None\n",
    "    for cat, pattern in CATEGORIZATION_PATTERNS.items():\n",
    "        if re.search(pattern, sample_name, re.IGNORECASE):\n",
    "            matched_category = cat\n",
    "            break\n",
    "    \n",
    "    if matched_category:\n",
    "        new_name = FILENAME_CREATORS[matched_category](sample_file, EVENT_NAME)\n",
    "        print(f\"\\nüìù Example transformation:\")\n",
    "        print(f\"   Original: {sample_name}\")\n",
    "        print(f\"   Category: {matched_category}\")\n",
    "        print(f\"   ‚Üí New:    {new_name}\")\n",
    "        print(f\"   ‚Üí Output: {DESTINATION_BASE}/{OUTPUT_DIRS[matched_category]}/{new_name}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Warning: Sample file doesn't match any category pattern:\")\n",
    "        print(f\"   File: {sample_name}\")\n",
    "        print(f\"   Add a pattern to CATEGORIZATION_PATTERNS to process this file type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: Initialize Processor and Preview\n",
    "\n",
    "Now let's set up the processor and preview all transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our simplified helper\n",
    "from notebooks.notebook_helpers import SimpleProcessor\n",
    "\n",
    "# Create full configuration with categorization patterns\n",
    "config = {\n",
    "    'event_name': EVENT_NAME,\n",
    "    'bucket': BUCKET,\n",
    "    'source_path': SOURCE_PATH,\n",
    "    'destination_base': DESTINATION_BASE,\n",
    "    'overwrite': OVERWRITE,\n",
    "    'verify': VERIFY,\n",
    "    'categorization_patterns': CATEGORIZATION_PATTERNS,  # IMPORTANT: Include patterns\n",
    "    'filename_creators': FILENAME_CREATORS,\n",
    "    'output_dirs': OUTPUT_DIRS,\n",
    "    'nodata_values': NODATA_VALUES\n",
    "}\n",
    "\n",
    "# Initialize processor\n",
    "processor = SimpleProcessor(config)\n",
    "\n",
    "# Connect to S3 (already connected, but needed for processor)\n",
    "if processor.connect_to_s3():\n",
    "    print(\"‚úÖ Processor ready\\n\")\n",
    "    \n",
    "    # Discover and categorize files\n",
    "    num_files = processor.discover_files()\n",
    "    \n",
    "    if num_files > 0:\n",
    "        # Show preview of transformations\n",
    "        processor.preview_processing()\n",
    "        \n",
    "        print(\"\\nüìå Review the transformations above.\")\n",
    "        print(\"   ‚Ä¢ Files will be saved to the directories specified in OUTPUT_DIRS\")\n",
    "        print(\"   ‚Ä¢ If files appear as 'uncategorized', add patterns to CATEGORIZATION_PATTERNS\")\n",
    "        print(\"   ‚Ä¢ When ready, proceed to Step 5 to process the files.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No files found to process.\")\n",
    "else:\n",
    "    print(\"‚ùå Could not initialize processor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 5: Process Files\n",
    "\n",
    "Run this cell to start processing all files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all files\n",
    "if 'num_files' in locals() and num_files > 0:\n",
    "    print(\"üöÄ Starting processing...\")\n",
    "    print(\"This may take several minutes depending on file sizes.\\n\")\n",
    "    \n",
    "    # Process everything\n",
    "    results = processor.process_all()\n",
    "    \n",
    "    # Display results\n",
    "    if not results.empty:\n",
    "        print(\"\\nüìä Processing Complete!\")\n",
    "        display(results) if 'display' in dir() else print(results)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No files to process. Complete Steps 1-4 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 6: Review Results (Optional)\n",
    "\n",
    "View detailed results and statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "if 'results' in locals() and not results.empty:\n",
    "    print(\"üìä PROCESSING STATISTICS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Success rate\n",
    "    total = len(results)\n",
    "    success = len(results[results['status'] == 'success'])\n",
    "    failed = len(results[results['status'] == 'failed'])\n",
    "    skipped = len(results[results['status'] == 'skipped'])\n",
    "    \n",
    "    print(f\"Total files: {total}\")\n",
    "    print(f\"‚úÖ Success: {success}\")\n",
    "    print(f\"‚ùå Failed: {failed}\")\n",
    "    print(f\"‚è≠Ô∏è Skipped: {skipped}\")\n",
    "    print(f\"\\nSuccess rate: {(success/total*100):.1f}%\")\n",
    "    \n",
    "    # Failed files\n",
    "    if failed > 0:\n",
    "        print(\"\\n‚ùå Failed files:\")\n",
    "        failed_df = results[results['status'] == 'failed']\n",
    "        for idx, row in failed_df.iterrows():\n",
    "            print(f\"  - {row['file']}: {row.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    # Processing times\n",
    "    if 'time_seconds' in results.columns:\n",
    "        success_df = results[results['status'] == 'success']\n",
    "        if not success_df.empty:\n",
    "            avg_time = success_df['time_seconds'].mean()\n",
    "            max_time = success_df['time_seconds'].max()\n",
    "            print(f\"\\n‚è±Ô∏è Timing:\")\n",
    "            print(f\"Average: {avg_time:.1f} seconds per file\")\n",
    "            print(f\"Slowest: {max_time:.1f} seconds\")\n",
    "else:\n",
    "    print(\"No results to analyze. Run Step 5 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Tips & Troubleshooting\n",
    "\n",
    "### Workflow Summary:\n",
    "1. **Configure** basic settings (Step 1)\n",
    "2. **List files** from S3 to see naming patterns (Step 2)\n",
    "3. **Define functions** to transform filenames (Step 3)\n",
    "4. **Preview** transformations (Step 4)\n",
    "5. **Process** all files (Step 5)\n",
    "6. **Review** results (Step 6)\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "1. **\"No files found\"**\n",
    "   - Check `SOURCE_PATH` in Step 1\n",
    "   - Verify bucket permissions\n",
    "   - Ensure files have `.tif` extension\n",
    "\n",
    "2. **Wrong filename transformations**\n",
    "   - Review actual filenames in Step 2\n",
    "   - Adjust functions in Step 3\n",
    "   - Re-run Step 4 to preview\n",
    "\n",
    "3. **Files being skipped**\n",
    "   - Files already exist in destination\n",
    "   - Set `OVERWRITE = True` in Step 1\n",
    "\n",
    "4. **Processing errors**\n",
    "   - Check AWS credentials\n",
    "   - Verify S3 write permissions\n",
    "   - Check available disk space for temp files\n",
    "\n",
    "### Need More Control?\n",
    "\n",
    "Use the full template at `disaster_processing_template.ipynb` for:\n",
    "- Manual chunk configuration\n",
    "- Custom compression settings\n",
    "- Detailed memory management\n",
    "- Advanced processing options"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
