{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåç Disaster COG Processing - VIIRS Flood\n",
    "\n",
    "This notebook converts VIIRS flood imagery to Cloud Optimized GeoTIFFs (COGs).\n",
    "\n",
    "## Workflow:\n",
    "1. Configure basic settings\n",
    "2. **List S3 files to see naming patterns**\n",
    "3. Define filename transformations based on what you see\n",
    "4. Preview and process\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Step 1: Basic Configuration\n",
    "\n",
    "Set your event details and S3 paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Basic configuration loaded\n",
      "Event: 202504_SevereWx_US\n",
      "Source: s3://nasa-disasters/drcs_activations/202504_SevereWx_US/viirs_flood\n",
      "Destination: s3://nasa-disasters/drcs_activations_new/\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# BASIC CONFIGURATION\n",
    "# ========================================\n",
    "\n",
    "# Event Details\n",
    "EVENT_NAME = '202504_SevereWx_US'  # Your disaster event name\n",
    "PRODUCT_NAME = 'viirs_flood'       # Product type\n",
    "\n",
    "# S3 Paths\n",
    "BUCKET = 'nasa-disasters'                                          # S3 bucket\n",
    "SOURCE_PATH = f'drcs_activations/{EVENT_NAME}/{PRODUCT_NAME}'      # Where your files are\n",
    "DESTINATION_BASE = 'drcs_activations_new'                          # Where to save COGs\n",
    "\n",
    "# Processing Options\n",
    "OVERWRITE = True  # Set to True to replace existing files\n",
    "VERIFY = True      # Set to True to verify results after processing\n",
    "\n",
    "print(\"‚úÖ Basic configuration loaded\")\n",
    "print(f\"Event: {EVENT_NAME}\")\n",
    "print(f\"Source: s3://{BUCKET}/{SOURCE_PATH}\")\n",
    "print(f\"Destination: s3://{BUCKET}/{DESTINATION_BASE}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 2: Connect to S3 and List Files\n",
    "\n",
    "Let's see what files are available before configuring filename transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Connecting to S3...\n",
      "‚úÖ Connected to S3\n",
      "\n",
      "üìÇ Files in s3://nasa-disasters/drcs_activations/202504_SevereWx_US/viirs_flood:\n",
      "============================================================\n",
      "Found 1 .tif files:\n",
      "\n",
      " 1. day_WATER_VIIRS_2025_04_07.tif                               (0.10 GB)\n",
      "\n",
      "============================================================\n",
      "\n",
      "üí° Use this information to create filename functions in Step 3\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path('..').resolve()))\n",
    "\n",
    "# Import S3 operations\n",
    "from core.s3_operations import (\n",
    "    initialize_s3_client,\n",
    "    list_s3_files,\n",
    "    get_file_size_from_s3\n",
    ")\n",
    "\n",
    "# Initialize S3 client\n",
    "print(\"üåê Connecting to S3...\")\n",
    "s3_client, _ = initialize_s3_client(bucket_name=BUCKET, verbose=False)\n",
    "\n",
    "if s3_client:\n",
    "    print(\"‚úÖ Connected to S3\\n\")\n",
    "    \n",
    "    # List all TIF files\n",
    "    print(f\"üìÇ Files in s3://{BUCKET}/{SOURCE_PATH}:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    files = list_s3_files(s3_client, BUCKET, SOURCE_PATH, suffix='.tif')\n",
    "    \n",
    "    if files:\n",
    "        print(f\"Found {len(files)} .tif files:\\n\")\n",
    "        for i, file_path in enumerate(files[:20], 1):  # Show first 20 for VIIRS\n",
    "            filename = os.path.basename(file_path)\n",
    "            try:\n",
    "                size_gb = get_file_size_from_s3(s3_client, BUCKET, file_path)\n",
    "                print(f\"{i:2}. {filename:<60} ({size_gb:.2f} GB)\")\n",
    "            except:\n",
    "                print(f\"{i:2}. {filename}\")\n",
    "        \n",
    "        if len(files) > 20:\n",
    "            print(f\"\\n... and {len(files) - 20} more files\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"\\nüí° Use this information to create filename functions in Step 3\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No .tif files found in the specified path.\")\n",
    "        print(\"   Check your SOURCE_PATH configuration.\")\n",
    "else:\n",
    "    print(\"‚ùå Could not connect to S3. Check your AWS credentials.\")\n",
    "    files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Step 3: Define Filename Transformations\n",
    "\n",
    "Based on the VIIRS files above, define how to transform the filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# FILENAME GENERATION FUNCTIONS FOR VIIRS\n",
    "# ========================================\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_date_from_viirs(filename):\n",
    "    \"\"\"Extract date from VIIRS filename.\n",
    "    VIIRS files often have format: day_WATER_VIIRS_2025_04_07.tif\n",
    "    \"\"\"\n",
    "    # Try to find YYYY_MM_DD pattern\n",
    "    pattern = r'(\\d{4})_(\\d{2})_(\\d{2})'\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        year, month, day = match.groups()\n",
    "        return f\"{year}-{month}-{day}\"\n",
    "    \n",
    "    # Try YYYYMMDD format as fallback\n",
    "    dates = re.findall(r'\\d{8}', filename)\n",
    "    if dates:\n",
    "        date_str = dates[0]\n",
    "        return f\"{date_str[0:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_viirs_flood_filename(original_path, event_name):\n",
    "    \"\"\"Create filename for VIIRS flood products.\n",
    "    Example: day_WATER_VIIRS_2025_04_07.tif ‚Üí 202504_SevereWx_US_VIIRS_WATER_2025-04-07_day.tif\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(original_path)\n",
    "    stem = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Extract date\n",
    "    date = extract_date_from_viirs(stem)\n",
    "    \n",
    "    # Determine if day or night\n",
    "    time_of_day = 'day' if 'day' in stem.lower() else 'night' if 'night' in stem.lower() else 'day'\n",
    "    \n",
    "    # Extract product type\n",
    "    product = 'WATER_VIIRS'\n",
    "    \n",
    "    if date:\n",
    "        return f\"{event_name}_{product}_{date}_{time_of_day}.tif\"\n",
    "    else:\n",
    "        # Fallback - keep original structure\n",
    "        return f\"{event_name}_{stem}.tif\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ VIIRS filename functions defined\n",
      "üìÇ Output directories configured:\n",
      "   ‚Ä¢ water ‚Üí VIIRS/water\n",
      "\n",
      "üìù Example transformations:\n",
      "\n",
      "1. Original: day_WATER_VIIRS_2025_04_07.tif\n",
      "   ‚Üí New:    202504_SevereWx_US_WATER_VIIRS_2025-04-07_day.tif\n"
     ]
    }
   ],
   "source": [
    "# Map product types to filename creators (THESE ARE REGEX PATTERNS)\n",
    "# For VIIRS, we'll use the specific function for all categories\n",
    "# IMPORTANT: Include 'other' to handle uncategorized files\n",
    "FILENAME_CREATORS = {\n",
    "    'water': create_viirs_flood_filename,\n",
    "}\n",
    "\n",
    "# Output directories for VIIRS products\n",
    "# IMPORTANT: Include 'other' to specify where uncategorized files go\n",
    "OUTPUT_DIRS = {\n",
    "\n",
    "    'water': 'VIIRS/water',\n",
    "\n",
    "}\n",
    "\n",
    "# No-data values for VIIRS (typically use auto-detect)\n",
    "NODATA_VALUES = {\n",
    "    # VIIRS flood products often use 0 or -9999\n",
    "    # Leave empty for auto-detection\n",
    "}\n",
    "\n",
    "print(\"‚úÖ VIIRS filename functions defined\")\n",
    "print(f\"üìÇ Output directories configured:\")\n",
    "for category, path in OUTPUT_DIRS.items():\n",
    "    print(f\"   ‚Ä¢ {category} ‚Üí {path}\")\n",
    "\n",
    "# Test with sample filenames\n",
    "if files:\n",
    "    print(\"\\nüìù Example transformations:\")\n",
    "    for i, file_path in enumerate(files[:3], 1):\n",
    "        sample_name = os.path.basename(file_path)\n",
    "        new_name = create_viirs_flood_filename(file_path, EVENT_NAME)\n",
    "        print(f\"\\n{i}. Original: {sample_name}\")\n",
    "        print(f\"   ‚Üí New:    {new_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: Initialize Processor and Preview\n",
    "\n",
    "Set up the processor and preview all transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All modules loaded successfully\n",
      "\n",
      "üåê Connecting to S3...\n",
      "‚úÖ Connected to S3 successfully\n",
      "‚úÖ Processor ready\n",
      "\n",
      "\n",
      "üîç Searching for files in: drcs_activations/202504_SevereWx_US/viirs_flood\n",
      "‚úÖ Found 1 files\n",
      "\n",
      "üìä File Categories:\n",
      "  ‚Ä¢ other: 1 files\n",
      "\n",
      "============================================================\n",
      "üìã PROCESSING PREVIEW\n",
      "============================================================\n",
      "\n",
      "Total files to process: 1\n",
      "Event: 202504_SevereWx_US\n",
      "Source: s3://nasa-disasters/drcs_activations/202504_SevereWx_US/viirs_flood\n",
      "Destination: s3://nasa-disasters/drcs_activations_new/\n",
      "\n",
      "File categories:\n",
      "  ‚Ä¢ other: 1 files\n",
      "    Example: day_WATER_VIIRS_2025_04_07.tif\n",
      "    ‚Üí 202504_SevereWx_US_day_WATER_VIIRS_2025_04_07_day.tif\n",
      "\n",
      "Settings:\n",
      "  ‚Ä¢ Compression: ZSTD level 22\n",
      "  ‚Ä¢ Overwrite existing: True\n",
      "  ‚Ä¢ Verify results: True\n",
      "============================================================\n",
      "\n",
      "üìå Review the transformations above.\n",
      "   If incorrect, adjust the filename functions in Step 3.\n",
      "   When ready, proceed to Step 5 to process.\n"
     ]
    }
   ],
   "source": [
    "# Import our simplified helper\n",
    "from notebooks.notebook_helpers import SimpleProcessor\n",
    "\n",
    "# Create full configuration\n",
    "config = {\n",
    "    'event_name': EVENT_NAME,\n",
    "    'bucket': BUCKET,\n",
    "    'source_path': SOURCE_PATH,\n",
    "    'destination_base': DESTINATION_BASE,\n",
    "    'overwrite': OVERWRITE,\n",
    "    'verify': VERIFY,\n",
    "    'filename_creators': FILENAME_CREATORS,\n",
    "    'output_dirs': OUTPUT_DIRS,\n",
    "    'nodata_values': NODATA_VALUES\n",
    "}\n",
    "\n",
    "# Initialize processor\n",
    "processor = SimpleProcessor(config)\n",
    "\n",
    "# Connect to S3\n",
    "if processor.connect_to_s3():\n",
    "    print(\"‚úÖ Processor ready\\n\")\n",
    "    \n",
    "    # Discover and categorize files\n",
    "    num_files = processor.discover_files()\n",
    "    \n",
    "    if num_files > 0:\n",
    "        # Show preview\n",
    "        processor.preview_processing()\n",
    "        \n",
    "        print(\"\\nüìå Review the transformations above.\")\n",
    "        print(\"   If incorrect, adjust the filename functions in Step 3.\")\n",
    "        print(\"   When ready, proceed to Step 5 to process.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No files found to process.\")\n",
    "else:\n",
    "    print(\"‚ùå Could not initialize processor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 5: Process Files\n",
    "\n",
    "Process all VIIRS files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting VIIRS flood data processing...\n",
      "This may take several minutes depending on file sizes.\n",
      "\n",
      "\n",
      "üöÄ Starting processing...\n",
      "\n",
      "üì¶ Processing other (1 files)\n",
      "‚ö†Ô∏è No filename creator for other, using default\n",
      "  ‚öôÔ∏è Processing: day_WATER_VIIRS_2025_04_07.tif (0.1GB)\n",
      "   [CHECK] Checking if file already exists in S3: s3://nasa-disasters/drcs_activations_new/misc/202504_SevereWx_US_day_WATER_VIIRS_2025_04_07_day.tif\n",
      "   [OVERWRITE] File exists but overwrite=True, reprocessing: 202504_SevereWx_US_day_WATER_VIIRS_2025_04_07_day.tif\n",
      "   [INFO] File size: 0.1 GB\n",
      "   [CONFIG] Using fixed chunks\n",
      "   [TEMP] Using temp directory: /home/jovyan/disasters-aws-conversion/templates/temp_cog\n",
      "   [MEMORY] Initial: 264.1 MB, Available: 27718.9 MB\n",
      "   [DOWNLOAD] Downloading from S3...\n",
      "   [DOWNLOAD] Downloading from S3: s3://nasa-disasters/drcs_activations/202504_SevereWx_US/viirs_flood/day_WATER_VIIRS_2025_04_07.tif\n",
      "   [DOWNLOAD] ‚úÖ Downloaded 104.0 MB to data_download/drcs_activations/202504_SevereWx_US/viirs_flood/day_WATER_VIIRS_2025_04_07.tif\n",
      "   [OPTIMIZED] Using GDAL COG driver for maximum performance\n",
      "   [NODATA] Data type: uint8\n",
      "   [NODATA] Using nodata value 0 for uint8 data\n",
      "   [GDAL-COG] Creating COG with native GDAL driver...\n",
      "   [GDAL-COG] Data type: uint8 ‚Üí Resampling: nearest, Overviews: mode\n",
      "   [GDAL-COG] Stage 1: Reprojecting to EPSG:4326 using nearest resampling...\n",
      "   [GDAL-COG] Stage 2: Creating COG...\n",
      "   [GDAL-COG] ‚úÖ COG with reprojection created successfully\n",
      "   [GDAL-COG] ‚úÖ COG created successfully\n",
      "   [UPLOAD] Uploading 5.5 MB to s3://nasa-disasters/drcs_activations_new/misc/202504_SevereWx_US_day_WATER_VIIRS_2025_04_07_day.tif\n",
      "   [UPLOAD] ‚úÖ Uploaded to s3://nasa-disasters/drcs_activations_new/misc/202504_SevereWx_US_day_WATER_VIIRS_2025_04_07_day.tif\n",
      "   [MEMORY] Final: 267.0 MB (Change: +2.9 MB)\n",
      "   [TIME] Total processing time: 5.9 seconds\n",
      "   [CLEANUP] Removed: data_download/drcs_activations/202504_SevereWx_US/viirs_flood/day_WATER_VIIRS_2025_04_07.tif\n",
      "   [CLEANUP] Removed: cog_202504_SevereWx_US_day_WATER_VIIRS_2025_04_07_day.tif\n",
      "  ‚úÖ Complete: 202504_SevereWx_US_day_WATER_VIIRS_2025_04_07_day.tif\n",
      "\n",
      "============================================================\n",
      "‚úÖ PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Results:\n",
      "  ‚úÖ Success: 1\n",
      "\n",
      "Processing time: 0.1 minutes\n",
      "Average per file: 6.2 seconds\n",
      "\n",
      "üìÅ Results saved to: output/202504_SevereWx_US/results_20250927_160207.csv\n",
      "============================================================\n",
      "\n",
      "‚úÖ VIIRS Processing Complete!\n",
      "                             file category   status  \\\n",
      "0  day_WATER_VIIRS_2025_04_07.tif    other  success   \n",
      "\n",
      "                                              output  time_seconds  \n",
      "0  202504_SevereWx_US_day_WATER_VIIRS_2025_04_07_...      6.187779  \n"
     ]
    }
   ],
   "source": [
    "# Process all files\n",
    "if 'num_files' in locals() and num_files > 0:\n",
    "    print(\"üöÄ Starting VIIRS flood data processing...\")\n",
    "    print(\"This may take several minutes depending on file sizes.\\n\")\n",
    "    \n",
    "    # Process everything\n",
    "    results = processor.process_all()\n",
    "    \n",
    "    # Display results\n",
    "    if not results.empty:\n",
    "        print(\"\\n‚úÖ VIIRS Processing Complete!\")\n",
    "        display(results) if 'display' in dir() else print(results)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No files to process. Complete Steps 1-4 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 6: Review Results\n",
    "\n",
    "Analyze processing results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "if 'results' in locals() and not results.empty:\n",
    "    print(\"üìä VIIRS PROCESSING STATISTICS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Success rate\n",
    "    total = len(results)\n",
    "    success = len(results[results['status'] == 'success'])\n",
    "    failed = len(results[results['status'] == 'failed'])\n",
    "    skipped = len(results[results['status'] == 'skipped'])\n",
    "    \n",
    "    print(f\"Total VIIRS files: {total}\")\n",
    "    print(f\"‚úÖ Success: {success}\")\n",
    "    print(f\"‚ùå Failed: {failed}\")\n",
    "    print(f\"‚è≠Ô∏è Skipped: {skipped}\")\n",
    "    print(f\"\\nSuccess rate: {(success/total*100):.1f}%\")\n",
    "    \n",
    "    # Failed files\n",
    "    if failed > 0:\n",
    "        print(\"\\n‚ùå Failed files:\")\n",
    "        failed_df = results[results['status'] == 'failed']\n",
    "        for idx, row in failed_df.iterrows():\n",
    "            print(f\"  - {row['file']}: {row.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    # Processing times\n",
    "    if 'time_seconds' in results.columns:\n",
    "        success_df = results[results['status'] == 'success']\n",
    "        if not success_df.empty:\n",
    "            avg_time = success_df['time_seconds'].mean()\n",
    "            max_time = success_df['time_seconds'].max()\n",
    "            total_time = success_df['time_seconds'].sum()\n",
    "            print(f\"\\n‚è±Ô∏è Timing:\")\n",
    "            print(f\"Total time: {total_time/60:.1f} minutes\")\n",
    "            print(f\"Average: {avg_time:.1f} seconds per file\")\n",
    "            print(f\"Slowest: {max_time:.1f} seconds\")\n",
    "else:\n",
    "    print(\"No results to analyze. Run Step 5 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° VIIRS-Specific Tips\n",
    "\n",
    "### VIIRS Flood Data Characteristics:\n",
    "- **Temporal coverage**: Daily observations (day and night)\n",
    "- **Spatial resolution**: ~375m\n",
    "- **Data values**: Often binary or categorical (water/no-water)\n",
    "- **No-data**: Usually 0 or -9999\n",
    "\n",
    "### Common VIIRS File Patterns:\n",
    "- `day_WATER_VIIRS_YYYY_MM_DD.tif`\n",
    "- `night_WATER_VIIRS_YYYY_MM_DD.tif`\n",
    "- `VIIRS_flood_YYYYMMDD.tif`\n",
    "\n",
    "### Processing Notes:\n",
    "1. VIIRS files are typically smaller than optical imagery\n",
    "2. Categorical data uses nearest-neighbor resampling\n",
    "3. COG compression is very effective on binary data\n",
    "4. Processing is usually faster than high-res optical\n",
    "\n",
    "### Troubleshooting:\n",
    "- If dates aren't extracted correctly, check the pattern in Step 3\n",
    "- VIIRS flood products may have different naming conventions\n",
    "- Adjust the `extract_date_from_viirs()` function as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
