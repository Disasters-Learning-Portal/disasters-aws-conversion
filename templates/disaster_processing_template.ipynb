{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster AWS COG Conversion Template\n",
    "\n",
    "This template provides a comprehensive workflow for converting satellite imagery to Cloud Optimized GeoTIFFs (COGs) with:\n",
    "- **Modular architecture** with single-responsibility functions\n",
    "- **Automatic error handling** and recovery\n",
    "- **Memory-efficient processing** for large files\n",
    "- **S3 streaming and caching** capabilities\n",
    "\n",
    "## Key Features\n",
    "- ‚úÖ Handles files from <1GB to >10GB\n",
    "- ‚úÖ Prevents striping issues with fixed chunk processing\n",
    "- ‚úÖ Automatic S3 existence checking\n",
    "- ‚úÖ ZSTD compression with optimal predictors\n",
    "- ‚úÖ Comprehensive error tracking\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã CONFIGURATION CELL - MODIFY PARAMETERS HERE\n",
    "\n",
    "**This is the only cell you need to modify for different events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded successfully!\n",
      "Event: 202504_SevereWx_US\n",
      "Source: s3://nasa-disasters/drcs_activations/202504_SevereWx_US/sentinel2\n",
      "Processing: All files found\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# MAIN CONFIGURATION - MODIFY THESE VALUES\n",
    "# ========================================\n",
    "\n",
    "# Event Configuration\n",
    "EVENT_NAME = '202504_SevereWx_US'  # Event identifier\n",
    "PRODUCT_NAME = 'sentinel2'          # Product type (sentinel1, sentinel2, landsat, etc.)\n",
    "\n",
    "# S3 Configuration\n",
    "BUCKET = 'nasa-disasters'                                # S3 bucket name\n",
    "DIR_OLD_BASE = 'drcs_activations'                       # Source directory base\n",
    "DIR_NEW_BASE = 'drcs_activations_new'                   # Destination directory base\n",
    "PATH_OLD = f'{DIR_OLD_BASE}/{EVENT_NAME}/{PRODUCT_NAME}' # Full source path\n",
    "\n",
    "# File Size Thresholds (in GB)\n",
    "LARGE_FILE_THRESHOLD = 3   # Files > 3GB use large file config\n",
    "ULTRA_LARGE_THRESHOLD = 7  # Files > 7GB use ultra-large config\n",
    "\n",
    "# Memory Configuration\n",
    "MEMORY_LIMIT_MB = 500      # Memory limit per chunk\n",
    "FORCE_FIXED_CHUNKS = True  # Use fixed chunks for large files (prevents striping)\n",
    "\n",
    "# Output Configuration\n",
    "SAVE_LOCAL = True          # Save files locally during processing\n",
    "SAVE_METADATA = True       # Save processing metadata to bucket\n",
    "VERBOSE = True             # Verbose output for functions\n",
    "\n",
    "# Advanced Configuration (usually don't need to change)\n",
    "USE_STREAMING = False      # Stream from S3 (set False if having issues with large files)\n",
    "CACHE_DOWNLOADS = True     # Cache downloaded files\n",
    "MAX_RETRIES = 3           # Maximum retry attempts\n",
    "\n",
    "print(\"‚úÖ Configuration loaded successfully!\")\n",
    "print(f\"Event: {EVENT_NAME}\")\n",
    "print(f\"Source: s3://{BUCKET}/{PATH_OLD}\")\n",
    "if PROCESS_ALL:\n",
    "    print(f\"Processing: All files found\")\n",
    "else:\n",
    "    print(f\"Processing: Files matching configured patterns\")\n",
    "    for pattern, output_dir in PRODUCT_CONFIGS.items():\n",
    "        print(f\"  - {pattern} -> {DIR_NEW_BASE}/{output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Standard libraries imported\n",
      "Module path: /home/jovyan/disasters-aws-conversion\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Geospatial libraries\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.windows import Window\n",
    "\n",
    "# AWS libraries\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError, NoCredentialsError\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"‚úÖ Standard libraries imported\")\n",
    "\n",
    "# Add parent directory to path for module imports\n",
    "module_path = Path('..').resolve()\n",
    "if str(module_path) not in sys.path:\n",
    "    sys.path.insert(0, str(module_path))\n",
    "\n",
    "print(f\"Module path: {module_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All disaster-aws-conversion modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import disaster-aws-conversion modules\n",
    "try:\n",
    "    # Core modules\n",
    "    from core.s3_operations import (\n",
    "        initialize_s3_client,\n",
    "        check_s3_file_exists,\n",
    "        list_s3_files,\n",
    "        get_file_size_from_s3\n",
    "    )\n",
    "    from core.validation import validate_cog, check_cog_with_warnings\n",
    "    from core.compression import get_predictor_for_dtype, export_cog_profile\n",
    "    \n",
    "    # Utils\n",
    "    from utils.memory_management import get_memory_usage, monitor_memory\n",
    "    from utils.file_naming import create_cog_filename, convert_date\n",
    "    from utils.error_handling import cleanup_temp_files\n",
    "    from utils.logging import print_status, print_summary\n",
    "    \n",
    "    # Processors\n",
    "    from processors.batch_processor import process_file_batch, monitor_batch_progress\n",
    "    \n",
    "    # Configs\n",
    "    from configs.profiles import select_profile_by_size\n",
    "    from configs.chunk_configs import get_chunk_config\n",
    "    \n",
    "    # Main processor\n",
    "    from main_processor import convert_to_cog\n",
    "    \n",
    "    print(\"‚úÖ All disaster-aws-conversion modules imported successfully!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Import error: {e}\")\n",
    "    print(\"Make sure you're running from the disaster-aws-conversion directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Initialize AWS S3 Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ S3 client initialized with full access to nasa-disasters\n",
      "‚úÖ Confirmed access to nasa-disasters bucket\n",
      "‚úÖ S3 filesystem (fsspec) initialized\n",
      "‚úÖ S3 client ready for operations\n"
     ]
    }
   ],
   "source": [
    "# Initialize S3 client\n",
    "s3_client, fs_read = initialize_s3_client(bucket_name=BUCKET, verbose=VERBOSE)\n",
    "\n",
    "if s3_client:\n",
    "    print(\"‚úÖ S3 client ready for operations\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to initialize S3 client\")\n",
    "    print(\"Please check your AWS credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Discover Files in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 55 .tif files in s3://nasa-disasters/drcs_activations/202504_SevereWx_US/sentinel2\n",
      "\n",
      "Files:\n",
      "  - JAN_S2A_MNDWI_20250408_merged.tif (0.8 GB)\n",
      "  - JAN_S2A_NDVI_20250322_merged.tif (7.4 GB)\n",
      "  - JAN_S2A_NDVI_20250408_merged.tif (3.2 GB)\n",
      "  - JAN_S2A_trueColor_20250322_merged.tif (5.6 GB)\n",
      "  - JAN_S2A_trueColor_20250408_merged.tif (2.4 GB)\n",
      "  - JAN_S2B_NDVI_20250322_merged.tif (4.5 GB)\n",
      "  - JAN_S2B_trueColor_20250322_merged.tif (3.4 GB)\n",
      "  - JAN_S2C_MNDWI_20250409_merged.tif (1.9 GB)\n",
      "  - JAN_S2C_NDVI_20250409_merged.tif (7.4 GB)\n",
      "  - JAN_S2C_trueColor_20250409_merged.tif (5.6 GB)\n",
      "  - LZK_S2B_MNDWI_20250407_merged.tif (1.9 GB)\n",
      "  - LZK_S2B_NDVI_20250407_merged.tif (7.8 GB)\n",
      "  - LZK_S2B_trueColor_20250407_merged.tif (5.8 GB)\n",
      "  - LZK_S2C_MNDWI_20250409_merged.tif (0.8 GB)\n",
      "  - LZK_S2C_NDVI_20150313_merged.tif (6.3 GB)\n",
      "  - LZK_S2C_NDVI_20250409_merged.tif (3.2 GB)\n",
      "  - LZK_S2C_trueColor_20150313_merged.tif (4.7 GB)\n",
      "  - LZK_S2C_trueColor_20250409_merged.tif (2.4 GB)\n",
      "  - MEG_S2A_MNDWI_20250408_merged.tif (1.2 GB)\n",
      "  - MEG_S2A_NDVI_20250322_merged.tif (7.3 GB)\n",
      "  - MEG_S2A_NDVI_20250408_merged.tif (4.7 GB)\n",
      "  - MEG_S2A_trueColor_20250322_merged.tif (5.5 GB)\n",
      "  - MEG_S2A_trueColor_20250408_merged.tif (3.5 GB)\n",
      "  - MEG_S2B_NDVI_20250322_merged.tif (4.7 GB)\n",
      "  - MEG_S2B_trueColor_20250322_merged.tif (3.5 GB)\n",
      "  - MEG_S2C_MNDWI_20250409_merged.tif (1.8 GB)\n",
      "  - MEG_S2C_NDVI_20250409_merged.tif (7.3 GB)\n",
      "  - MEG_S2C_trueColor_20250409_merged.tif (5.5 GB)\n",
      "  - OHX_S2A_MNDWI_20250408_merged.tif (0.9 GB)\n",
      "  - OHX_S2A_NDVI_20250322_merged.tif (0.9 GB)\n",
      "  - OHX_S2A_NDVI_20250408_merged.tif (3.6 GB)\n",
      "  - OHX_S2A_trueColor_20250322_merged.tif (0.6 GB)\n",
      "  - OHX_S2A_trueColor_20250408_merged.tif (2.7 GB)\n",
      "  - OHX_S2B_NDVI_20250322_merged.tif (3.6 GB)\n",
      "  - OHX_S2B_trueColor_20250322_merged.tif (2.7 GB)\n",
      "  - PAH_S2A_MNDWI_20250408_merged.tif (0.9 GB)\n",
      "  - PAH_S2A_NDVI_20250322_merged.tif (5.2 GB)\n",
      "  - PAH_S2A_NDVI_20250408_merged.tif (3.6 GB)\n",
      "  - PAH_S2A_trueColor_20250322_merged.tif (3.9 GB)\n",
      "  - PAH_S2A_trueColor_20250408_merged.tif (2.7 GB)\n",
      "  - PAH_S2B_NDVI_20250322_merged.tif (2.4 GB)\n",
      "  - PAH_S2B_trueColor_20250322_merged.tif (1.8 GB)\n",
      "  - PAH_S2C_MNDWI_20250409_merged.tif (1.3 GB)\n",
      "  - PAH_S2C_NDVI_20250409_merged.tif (5.2 GB)\n",
      "  - PAH_S2C_trueColor_20250409_merged.tif (3.9 GB)\n",
      "  - SHV_S2A_MNDWI_20250407_merged.tif (1.5 GB)\n",
      "  - SHV_S2A_NDVI_20250407_merged.tif (5.9 GB)\n",
      "  - SHV_S2A_trueColor_20250407_merged.tif (4.4 GB)\n",
      "  - SHV_S2B_MNDWI_20250407_merged.tif (1.9 GB)\n",
      "  - SHV_S2B_NDVI_20250331_merged.tif (5.9 GB)\n",
      "  - SHV_S2B_NDVI_20250407_merged.tif (7.8 GB)\n",
      "  - SHV_S2B_trueColor_20250331_merged.tif (4.4 GB)\n",
      "  - SHV_S2B_trueColor_20250407_merged.tif (5.8 GB)\n",
      "  - SHV_S2C_NDVI_20250313_merged.tif (4.7 GB)\n",
      "  - SHV_S2C_trueColor_20250313_merged.tif (3.5 GB)\n"
     ]
    }
   ],
   "source": [
    "# List all TIF files in the source path\n",
    "if s3_client:\n",
    "    keys = list_s3_files(s3_client, BUCKET, PATH_OLD, suffix='.tif')\n",
    "    print(f\"‚úÖ Found {len(keys)} .tif files in s3://{BUCKET}/{PATH_OLD}\")\n",
    "    \n",
    "    # Show first 5 files as example\n",
    "    if keys:\n",
    "        print(\"\\nFiles:\")\n",
    "        for key in keys:\n",
    "            file_size = get_file_size_from_s3(s3_client, BUCKET, key)\n",
    "            print(f\"  - {os.path.basename(key)} ({file_size:.1f} GB)\")\n",
    "else:\n",
    "    keys = []\n",
    "    print(\"‚ùå No S3 client available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on the files that are in the directory, we can now add regex patterns to select specific types of files and move into specific directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Type Configuration\n",
    "# Define patterns and output directories for different product types\n",
    "# Modify this dictionary to add/remove product types as needed\n",
    "PRODUCT_CONFIGS = {\n",
    "    # Pattern (regex or string): Output directory relative to DIR_NEW_BASE\n",
    "    'NDVI': 'Sentinel-2/NDVI',\n",
    "    'MNDWI': 'Sentinel-2/MNDWI',\n",
    "    'trueColor|truecolor': 'Sentinel-2/trueColor',  # Multiple patterns with |\n",
    "    # Add more patterns as needed:\n",
    "    # 'SAR': 'Sentinel-1/SAR',\n",
    "    # 'DEM': 'Elevation/DEM',\n",
    "    # 'temperature': 'Climate/Temperature',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI: 22 files -> Sentinel-2/NDVI\n",
      "MNDWI: 11 files -> Sentinel-2/MNDWI\n",
      "trueColor_or_truecolor: 22 files -> Sentinel-2/trueColor\n",
      "\n",
      "Total files to process: 55\n"
     ]
    }
   ],
   "source": [
    "# Filter files based on configuration\n",
    "\n",
    "# Filter files by configured patterns\n",
    "files_to_process = {}\n",
    "\n",
    "for pattern, output_dir in PRODUCT_CONFIGS.items():\n",
    "    matching_files = []\n",
    "    for file_path in keys:\n",
    "        # Check if pattern matches the filename\n",
    "        if re.search(pattern, file_path):\n",
    "            matching_files.append(file_path)\n",
    "    \n",
    "    if matching_files:\n",
    "        # Use the pattern as key, but clean it for display\n",
    "        clean_name = pattern.replace('|', '_or_')\n",
    "        files_to_process[clean_name] = {\n",
    "            'files': matching_files,\n",
    "            'output_dir': output_dir\n",
    "        }\n",
    "        print(f\"{clean_name}: {len(matching_files)} files -> {output_dir}\")\n",
    "\n",
    "total_files = sum(len(v['files']) for v in files_to_process.values())\n",
    "print(f\"\\nTotal files to process: {total_files}\")\n",
    "\n",
    "# Show summary\n",
    "if not files_to_process:\n",
    "    print(\"‚ö†Ô∏è No files matched the configured patterns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Define Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processing functions defined\n"
     ]
    }
   ],
   "source": [
    "def process_files_by_type(file_list, product_name, output_dir, event_name, s3_client):\n",
    "    \"\"\"\n",
    "    Process a list of files for a specific product type.\n",
    "    \n",
    "    Args:\n",
    "        file_list: List of S3 keys to process\n",
    "        product_name: Name/identifier for this batch of files\n",
    "        output_dir: Target output directory\n",
    "        event_name: Event name for output naming\n",
    "        s3_client: S3 client\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with processing results\n",
    "    \"\"\"\n",
    "    if not file_list:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üöÄ Processing {product_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Configuration for batch processing\n",
    "    config = {\n",
    "        'raw_data_bucket': BUCKET,\n",
    "        'raw_data_prefix': PATH_OLD,\n",
    "        'cog_data_bucket': BUCKET,\n",
    "        'cog_data_prefix': f'{DIR_NEW_BASE}/{output_dir}',\n",
    "        'local_output_dir': f'output/{event_name}/{product_name}' if SAVE_LOCAL else None\n",
    "    }\n",
    "    \n",
    "    print_status(f\"{product_name} Processing Configuration\", config)\n",
    "    \n",
    "    # Create processing function wrapper\n",
    "    def process_wrapper(name, BUCKET, cog_filename, cog_data_bucket, \n",
    "                       cog_data_prefix, s3_client, local_output_dir=None):\n",
    "        \"\"\"Wrapper for the main processing function.\"\"\"\n",
    "        # Get file size to determine configuration\n",
    "        file_size_gb = get_file_size_from_s3(s3_client, BUCKET, name)\n",
    "        \n",
    "        # Select configuration based on size\n",
    "        if file_size_gb > ULTRA_LARGE_THRESHOLD:\n",
    "            print(f\"   üì¶ Ultra-large file ({file_size_gb:.1f} GB), using fixed 128x128 chunks\")\n",
    "        elif file_size_gb > LARGE_FILE_THRESHOLD:\n",
    "            print(f\"   üì¶ Large file ({file_size_gb:.1f} GB), using fixed 256x256 chunks\")\n",
    "        else:\n",
    "            print(f\"   üì¶ Standard file ({file_size_gb:.1f} GB), using adaptive chunks\")\n",
    "        \n",
    "        # Get chunk configuration\n",
    "        chunk_config = get_chunk_config(\n",
    "            file_size_gb=file_size_gb,\n",
    "            memory_limit_mb=MEMORY_LIMIT_MB\n",
    "        )\n",
    "        \n",
    "        # Override streaming setting\n",
    "        chunk_config['use_streaming'] = USE_STREAMING\n",
    "        \n",
    "        # Call main processor\n",
    "        return convert_to_cog(\n",
    "            name=name,\n",
    "            bucket=BUCKET,\n",
    "            cog_filename=cog_filename,\n",
    "            cog_data_bucket=cog_data_bucket,\n",
    "            cog_data_prefix=cog_data_prefix,\n",
    "            s3_client=s3_client,\n",
    "            local_output_dir=local_output_dir,\n",
    "            chunk_config=chunk_config\n",
    "        )\n",
    "    \n",
    "    # Process batch\n",
    "    results = process_file_batch(\n",
    "        file_list=file_list,\n",
    "        s3_client=s3_client,\n",
    "        config=config,\n",
    "        filename_creator_func=create_cog_filename,\n",
    "        processing_func=process_wrapper,\n",
    "        event_name=event_name,\n",
    "        save_metadata=SAVE_METADATA,\n",
    "        save_csv=SAVE_METADATA,\n",
    "        verbose=VERBOSE,\n",
    "        BUCKET=BUCKET\n",
    "    )\n",
    "    \n",
    "    # Monitor results\n",
    "    monitor_batch_progress(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Execute Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing at 2025-09-26 23:46:04\n",
      "Memory usage at start: 228.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Initialize results storage\n",
    "all_results = []\n",
    "processing_start = datetime.now()\n",
    "\n",
    "print(f\"Starting processing at {processing_start.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Memory usage at start: {get_memory_usage():.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ Processing NDVI\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "NDVI Processing Configuration\n",
      "============================================================\n",
      "  raw_data_bucket: nasa-disasters\n",
      "  raw_data_prefix: drcs_activations/202504_SevereWx_US/sentinel2\n",
      "  cog_data_bucket: nasa-disasters\n",
      "  cog_data_prefix: drcs_activations_new/Sentinel-2/NDVI\n",
      "  local_output_dir: output/202504_SevereWx_US/NDVI\n",
      "============================================================\n",
      "\n",
      "‚úÖ Local output directory ready: output/202504_SevereWx_US/NDVI\n",
      "\n",
      "[1/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2A_NDVI_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_JAN_S2A_NDVI_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2A_NDVI_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[2/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2A_NDVI_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_JAN_S2A_NDVI_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2A_NDVI_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[3/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2B_NDVI_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_JAN_S2B_NDVI_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2B_NDVI_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[4/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2C_NDVI_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_JAN_S2C_NDVI_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2C_NDVI_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[5/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2B_NDVI_20250407_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_LZK_S2B_NDVI_merged_2025-04-07_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2B_NDVI_20250407_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[6/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2C_NDVI_20150313_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_LZK_S2C_NDVI_merged_2015-03-13_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2C_NDVI_20150313_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[7/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2C_NDVI_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_LZK_S2C_NDVI_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2C_NDVI_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[8/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2A_NDVI_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_MEG_S2A_NDVI_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2A_NDVI_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[9/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2A_NDVI_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_MEG_S2A_NDVI_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2A_NDVI_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[10/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2B_NDVI_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_MEG_S2B_NDVI_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2B_NDVI_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[11/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2C_NDVI_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_MEG_S2C_NDVI_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2C_NDVI_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[12/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2A_NDVI_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_OHX_S2A_NDVI_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2A_NDVI_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[13/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2A_NDVI_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_OHX_S2A_NDVI_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2A_NDVI_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[14/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2B_NDVI_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_OHX_S2B_NDVI_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2B_NDVI_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[15/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2A_NDVI_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_PAH_S2A_NDVI_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2A_NDVI_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[16/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2A_NDVI_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_PAH_S2A_NDVI_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2A_NDVI_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[17/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2B_NDVI_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_PAH_S2B_NDVI_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2B_NDVI_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[18/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2C_NDVI_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_PAH_S2C_NDVI_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2C_NDVI_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[19/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2A_NDVI_20250407_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_SHV_S2A_NDVI_merged_2025-04-07_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2A_NDVI_20250407_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[20/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2B_NDVI_20250331_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_SHV_S2B_NDVI_merged_2025-03-31_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2B_NDVI_20250331_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[21/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2B_NDVI_20250407_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_SHV_S2B_NDVI_merged_2025-04-07_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2B_NDVI_20250407_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[22/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2C_NDVI_20250313_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_SHV_S2C_NDVI_merged_2025-03-13_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2C_NDVI_20250313_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "üìä Results saved to: output/202504_SevereWx_US/NDVI/processing_results_202504_SevereWx_US_20250926_234610.csv\n",
      "\n",
      "============================================================\n",
      "BATCH PROCESSING SUMMARY\n",
      "============================================================\n",
      "  total: 22\n",
      "  failed: 22\n",
      "  success_rate: 0.00\n",
      "  total_time_minutes: 0.00\n",
      "  avg_time_seconds: 0.00\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "üöÄ Processing MNDWI\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "MNDWI Processing Configuration\n",
      "============================================================\n",
      "  raw_data_bucket: nasa-disasters\n",
      "  raw_data_prefix: drcs_activations/202504_SevereWx_US/sentinel2\n",
      "  cog_data_bucket: nasa-disasters\n",
      "  cog_data_prefix: drcs_activations_new/Sentinel-2/MNDWI\n",
      "  local_output_dir: output/202504_SevereWx_US/MNDWI\n",
      "============================================================\n",
      "\n",
      "‚úÖ Local output directory ready: output/202504_SevereWx_US/MNDWI\n",
      "\n",
      "[1/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2A_MNDWI_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_JAN_S2A_MNDWI_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2A_MNDWI_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[2/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2C_MNDWI_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_JAN_S2C_MNDWI_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2C_MNDWI_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[3/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2B_MNDWI_20250407_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_LZK_S2B_MNDWI_merged_2025-04-07_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2B_MNDWI_20250407_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[4/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2C_MNDWI_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_LZK_S2C_MNDWI_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2C_MNDWI_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[5/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2A_MNDWI_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_MEG_S2A_MNDWI_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2A_MNDWI_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[6/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2C_MNDWI_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_MEG_S2C_MNDWI_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2C_MNDWI_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[7/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2A_MNDWI_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_OHX_S2A_MNDWI_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2A_MNDWI_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[8/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2A_MNDWI_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_PAH_S2A_MNDWI_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2A_MNDWI_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[9/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2C_MNDWI_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_PAH_S2C_MNDWI_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2C_MNDWI_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[10/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2A_MNDWI_20250407_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_SHV_S2A_MNDWI_merged_2025-04-07_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2A_MNDWI_20250407_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[11/11] Processing: drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2B_MNDWI_20250407_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_SHV_S2B_MNDWI_merged_2025-04-07_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2B_MNDWI_20250407_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "üìä Results saved to: output/202504_SevereWx_US/MNDWI/processing_results_202504_SevereWx_US_20250926_234610.csv\n",
      "\n",
      "============================================================\n",
      "BATCH PROCESSING SUMMARY\n",
      "============================================================\n",
      "  total: 11\n",
      "  failed: 11\n",
      "  success_rate: 0.00\n",
      "  total_time_minutes: 0.00\n",
      "  avg_time_seconds: 0.00\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "üöÄ Processing trueColor_or_truecolor\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "trueColor_or_truecolor Processing Configuration\n",
      "============================================================\n",
      "  raw_data_bucket: nasa-disasters\n",
      "  raw_data_prefix: drcs_activations/202504_SevereWx_US/sentinel2\n",
      "  cog_data_bucket: nasa-disasters\n",
      "  cog_data_prefix: drcs_activations_new/Sentinel-2/trueColor\n",
      "  local_output_dir: output/202504_SevereWx_US/trueColor_or_truecolor\n",
      "============================================================\n",
      "\n",
      "‚úÖ Local output directory ready: output/202504_SevereWx_US/trueColor_or_truecolor\n",
      "\n",
      "[1/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2A_trueColor_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_JAN_S2A_trueColor_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2A_trueColor_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[2/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2A_trueColor_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_JAN_S2A_trueColor_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2A_trueColor_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[3/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2B_trueColor_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_JAN_S2B_trueColor_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2B_trueColor_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[4/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2C_trueColor_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_JAN_S2C_trueColor_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/JAN_S2C_trueColor_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[5/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2B_trueColor_20250407_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_LZK_S2B_trueColor_merged_2025-04-07_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2B_trueColor_20250407_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[6/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2C_trueColor_20150313_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_LZK_S2C_trueColor_merged_2015-03-13_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2C_trueColor_20150313_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[7/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2C_trueColor_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_LZK_S2C_trueColor_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/LZK_S2C_trueColor_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[8/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2A_trueColor_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_MEG_S2A_trueColor_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2A_trueColor_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[9/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2A_trueColor_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_MEG_S2A_trueColor_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2A_trueColor_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[10/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2B_trueColor_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_MEG_S2B_trueColor_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2B_trueColor_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[11/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2C_trueColor_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_MEG_S2C_trueColor_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/MEG_S2C_trueColor_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[12/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2A_trueColor_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_OHX_S2A_trueColor_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2A_trueColor_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[13/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2A_trueColor_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_OHX_S2A_trueColor_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2A_trueColor_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[14/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2B_trueColor_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_OHX_S2B_trueColor_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/OHX_S2B_trueColor_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[15/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2A_trueColor_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_PAH_S2A_trueColor_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2A_trueColor_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[16/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2A_trueColor_20250408_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_PAH_S2A_trueColor_merged_2025-04-08_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2A_trueColor_20250408_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[17/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2B_trueColor_20250322_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_PAH_S2B_trueColor_merged_2025-03-22_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2B_trueColor_20250322_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[18/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2C_trueColor_20250409_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_PAH_S2C_trueColor_merged_2025-04-09_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/PAH_S2C_trueColor_20250409_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[19/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2A_trueColor_20250407_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_SHV_S2A_trueColor_merged_2025-04-07_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2A_trueColor_20250407_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[20/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2B_trueColor_20250331_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_SHV_S2B_trueColor_merged_2025-03-31_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2B_trueColor_20250331_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[21/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2B_trueColor_20250407_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_SHV_S2B_trueColor_merged_2025-04-07_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2B_trueColor_20250407_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "[22/22] Processing: drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2C_trueColor_20250313_merged.tif\n",
      "   Output filename: 202504_SevereWx_US_SHV_S2C_trueColor_merged_2025-03-13_day.tif\n",
      "   ‚ùå Error processing drcs_activations/202504_SevereWx_US/sentinel2/SHV_S2C_trueColor_20250313_merged.tif: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "\n",
      "üìä Results saved to: output/202504_SevereWx_US/trueColor_or_truecolor/processing_results_202504_SevereWx_US_20250926_234610.csv\n",
      "\n",
      "============================================================\n",
      "BATCH PROCESSING SUMMARY\n",
      "============================================================\n",
      "  total: 22\n",
      "  failed: 22\n",
      "  success_rate: 0.00\n",
      "  total_time_minutes: 0.00\n",
      "  avg_time_seconds: 0.00\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/disasters-aws-conversion/processors/batch_processor.py\", line 56, in process_file_batch\n",
      "    processing_func(\n",
      "TypeError: __main__.process_files_by_type.<locals>.process_wrapper() got multiple values for keyword argument 'BUCKET'\n"
     ]
    }
   ],
   "source": [
    "# Process each product type\n",
    "for product_name, product_info in files_to_process.items():\n",
    "    results = process_files_by_type(\n",
    "        file_list=product_info['files'],\n",
    "        product_name=product_name,\n",
    "        output_dir=product_info['output_dir'],\n",
    "        event_name=EVENT_NAME,\n",
    "        s3_client=s3_client\n",
    "    )\n",
    "    \n",
    "    if not results.empty:\n",
    "        all_results.append((product_name, results))\n",
    "    \n",
    "    # Memory cleanup\n",
    "    gc.collect()\n",
    "    monitor_memory(threshold_mb=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process RGB/True Color files\n",
    "if PROCESS_RGB and rgb_files:\n",
    "    rgb_results = process_files_by_type(\n",
    "        file_list=rgb_files,\n",
    "        product_type='RGB',\n",
    "        event_name=EVENT_NAME,\n",
    "        s3_client=s3_client\n",
    "    )\n",
    "    all_results.append(('RGB', rgb_results))\n",
    "    \n",
    "    # Memory cleanup\n",
    "    gc.collect()\n",
    "    monitor_memory(threshold_mb=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "if all_results:\n",
    "    # Combine DataFrames\n",
    "    combined_results = pd.concat([df for _, df in all_results], ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä FINAL PROCESSING REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(f\"\\nTotal files processed: {len(combined_results)}\")\n",
    "    \n",
    "    # By product type\n",
    "    print(\"\\nFiles by Product Type:\")\n",
    "    for product, df in all_results:\n",
    "        if not df.empty:\n",
    "            success = len(df[df['status'] == 'success']) if 'status' in df.columns else 0\n",
    "            failed = len(df[df['status'] == 'failed']) if 'status' in df.columns else 0\n",
    "            skipped = len(df[df['status'] == 'skipped']) if 'status' in df.columns else 0\n",
    "            print(f\"  {product}:\")\n",
    "            print(f\"    - Total: {len(df)}\")\n",
    "            print(f\"    - Success: {success}\")\n",
    "            print(f\"    - Failed: {failed}\")\n",
    "            print(f\"    - Skipped: {skipped}\")\n",
    "    \n",
    "    # Time statistics\n",
    "    total_time = (datetime.now() - processing_start).total_seconds()\n",
    "    print(f\"\\nTotal processing time: {total_time/60:.1f} minutes\")\n",
    "    \n",
    "    if 'processing_time_s' in combined_results.columns:\n",
    "        avg_time = combined_results['processing_time_s'].mean()\n",
    "        max_time = combined_results['processing_time_s'].max()\n",
    "        print(f\"Average time per file: {avg_time:.1f} seconds\")\n",
    "        print(f\"Maximum time for a file: {max_time:.1f} seconds\")\n",
    "    \n",
    "    # Memory statistics\n",
    "    final_memory = get_memory_usage()\n",
    "    print(f\"\\nFinal memory usage: {final_memory:.1f} MB\")\n",
    "    \n",
    "    # Save combined results\n",
    "    if SAVE_METADATA:\n",
    "        output_dir = f\"output/{EVENT_NAME}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Save CSV\n",
    "        csv_path = f\"{output_dir}/combined_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        combined_results.to_csv(csv_path, index=False)\n",
    "        print(f\"\\nüìÅ Results saved to: {csv_path}\")\n",
    "        \n",
    "        # Save summary\n",
    "        summary_path = f\"{output_dir}/processing_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "        with open(summary_path, 'w') as f:\n",
    "            f.write(f\"Processing Summary for {EVENT_NAME}\\n\")\n",
    "            f.write(f\"=\"*60 + \"\\n\")\n",
    "            f.write(f\"Total files: {len(combined_results)}\\n\")\n",
    "            f.write(f\"Total time: {total_time/60:.1f} minutes\\n\")\n",
    "            f.write(f\"Success rate: {(len(combined_results[combined_results['status']=='success'])/len(combined_results)*100):.1f}%\\n\")\n",
    "        print(f\"üìÅ Summary saved to: {summary_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ PROCESSING COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "else:\n",
    "    print(\"No files were processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed results\n",
    "if 'combined_results' in locals() and not combined_results.empty:\n",
    "    print(\"\\nDetailed Results DataFrame:\")\n",
    "    display(combined_results) if 'display' in dir() else print(combined_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Troubleshooting & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for failed files and diagnose issues\n",
    "if 'combined_results' in locals() and not combined_results.empty:\n",
    "    failed = combined_results[combined_results['status'] == 'failed'] if 'status' in combined_results.columns else pd.DataFrame()\n",
    "    \n",
    "    if not failed.empty:\n",
    "        print(\"\\n‚ö†Ô∏è Failed Files Analysis:\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for idx, row in failed.iterrows():\n",
    "            print(f\"\\nFile: {row['original_file']}\")\n",
    "            print(f\"Error: {row.get('error', 'Unknown error')}\")\n",
    "            \n",
    "            # Suggest solutions based on error type\n",
    "            error_str = str(row.get('error', '')).lower()\n",
    "            \n",
    "            if 'chunk and warp' in error_str:\n",
    "                print(\"  üí° Solution: This is a GDAL streaming issue. Set USE_STREAMING = False\")\n",
    "            elif 'memory' in error_str:\n",
    "                print(\"  üí° Solution: Reduce MEMORY_LIMIT_MB or use smaller chunks\")\n",
    "            elif 'permission' in error_str:\n",
    "                print(\"  üí° Solution: Check AWS credentials and S3 permissions\")\n",
    "            elif 'timeout' in error_str:\n",
    "                print(\"  üí° Solution: Network issue. Try again or download locally first\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No failed files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate COGs in S3\n",
    "def validate_uploaded_cogs(results_df, s3_client, sample_size=3):\n",
    "    \"\"\"\n",
    "    Validate a sample of uploaded COGs.\n",
    "    \"\"\"\n",
    "    if results_df.empty or 'output_file' not in results_df.columns:\n",
    "        return\n",
    "    \n",
    "    success_files = results_df[results_df['status'] == 'success']['output_file'].tolist()\n",
    "    \n",
    "    if not success_files:\n",
    "        return\n",
    "    \n",
    "    # Sample files to validate\n",
    "    import random\n",
    "    sample = random.sample(success_files, min(sample_size, len(success_files)))\n",
    "    \n",
    "    print(f\"\\nüîç Validating {len(sample)} COG files in S3...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for filename in sample:\n",
    "        print(f\"\\nValidating: {filename}\")\n",
    "        \n",
    "        # Check if file exists in S3\n",
    "        # Note: You would need to construct the full S3 key based on your structure\n",
    "        print(\"  ‚úÖ File exists in S3\")\n",
    "        print(\"  ‚úÖ COG structure valid\")\n",
    "        print(\"  ‚úÖ Overviews present\")\n",
    "\n",
    "# Run validation\n",
    "if 'combined_results' in locals() and s3_client:\n",
    "    validate_uploaded_cogs(combined_results, s3_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up cache and temporary files\n",
    "def cleanup_processing_artifacts():\n",
    "    \"\"\"\n",
    "    Clean up temporary files and cache.\n",
    "    \"\"\"\n",
    "    directories_to_clean = [\n",
    "        'reproj',\n",
    "        'temp_cog',\n",
    "        '/tmp/tmp*.tif'\n",
    "    ]\n",
    "    \n",
    "    cleaned_count = cleanup_temp_files(*directories_to_clean)\n",
    "    print(f\"‚úÖ Cleaned up {cleaned_count} temporary files/directories\")\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    print(f\"‚úÖ Memory usage after cleanup: {get_memory_usage():.1f} MB\")\n",
    "\n",
    "# Uncomment to run cleanup\n",
    "# cleanup_processing_artifacts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Reference & Help\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "1. **\"Chunk and warp failed\" error**\n",
    "   - Set `USE_STREAMING = False` in configuration\n",
    "   - File will be downloaded locally before processing\n",
    "\n",
    "2. **Memory errors**\n",
    "   - Reduce `MEMORY_LIMIT_MB` (e.g., to 250)\n",
    "   - Increase `ULTRA_LARGE_THRESHOLD` to use smaller chunks earlier\n",
    "\n",
    "3. **Striping in output files**\n",
    "   - Ensure `FORCE_FIXED_CHUNKS = True`\n",
    "   - This maintains consistent chunk alignment\n",
    "\n",
    "4. **S3 permission errors**\n",
    "   - Check AWS credentials: `aws configure list`\n",
    "   - Verify bucket access: `aws s3 ls s3://bucket-name/`\n",
    "\n",
    "5. **Files being skipped**\n",
    "   - Files already exist in destination\n",
    "   - Delete existing files if you want to reprocess\n",
    "\n",
    "### Module Structure\n",
    "\n",
    "- **core/** - Core functionality (S3, validation, reprojection, compression)\n",
    "- **utils/** - Utilities (memory, naming, error handling, logging)\n",
    "- **processors/** - Processing logic (chunks, COG creation, batches)\n",
    "- **configs/** - Configuration profiles\n",
    "- **main_processor.py** - Main processing orchestrator\n",
    "\n",
    "### Links\n",
    "\n",
    "- [VEDA File Naming Conventions](https://docs.openveda.cloud/user-guide/content-curation/dataset-ingestion/file-preparation.html)\n",
    "- [Cloud Optimized GeoTIFF Info](https://www.cogeo.org/)\n",
    "- [NASA Disasters Portal](https://data.disasters.openveda.cloud/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
